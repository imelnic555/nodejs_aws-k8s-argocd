name: Deploy EKS & ArgoCD with NGINX Ingress

on:
  push:
    branches:
      - master

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: us-west-2
      CLUSTER_NAME: my-cluster
      GHPTOKEN: ${{ secrets.GHPTOKEN }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2

      - name: Make Deployment Script Executable
        run: chmod +x scripts/Aws_K8s_Argocd.sh

      - name: Run Deployment Script
        run: ./scripts/Aws_K8s_Argocd.sh

      - name: Terraform Init & Apply
        run: |
          cd terraform
          terraform init
          terraform apply -auto-approve

      - name: Update kubeconfig
        run: aws eks --region us-west-2 update-kubeconfig --name my-cluster

      - name: Create ArgoCD namespace
        run: |
          kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -

      

      - name: Install ArgoCD
        run: |
          kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

      - name: Ensure ArgoCD Admin Secret Exists
        run: |
          if ! kubectl get secret argocd-secret -n argocd; then
            echo "🔐 Creating ArgoCD admin secret..."
            kubectl create secret generic argocd-secret -n argocd \
              --from-literal=admin.password='$2a0$wEJ.NXBfjRj9JQ0QeqA1OuD4/2H6pRxH3p80fD/QFOhH8sD/jq12y'
          else
            echo "✅ ArgoCD admin secret already exists."
          fi

      - name: Wait for ArgoCD Pods to be Ready
        run: |
          echo "Waiting for all ArgoCD pods to be ready..."
          kubectl wait --for=condition=Available=True deployment -l app.kubernetes.io/component=server -n argocd --timeout=600s
      - name: Wait for All ArgoCD Pods to be Ready
        run: |
          echo "🔍 Waiting for all ArgoCD pods to be fully ready..."
          for i in {1..30}; do
            READY_PODS=$(kubectl get pods -n argocd --no-headers | awk '{print $2}' | grep -c "1/1")
            TOTAL_PODS=$(kubectl get pods -n argocd --no-headers | wc -l)

            if [[ "$READY_PODS" -eq "$TOTAL_PODS" ]]; then
              echo "✅ All ArgoCD pods are ready!"
              exit 0
            fi

            echo "⏳ Waiting... $READY_PODS/$TOTAL_PODS pods are ready."
            sleep 10
          done

          echo "❌ Error: ArgoCD pods failed to reach 1/1 READY state."
          exit 1
      - name: Restart ArgoCD Pods if Needed
        run: |
          echo "♻️ Restarting ArgoCD pods if necessary..."
          if [[ $(kubectl get pods -n argocd | grep -c 'Running') -lt 5 ]]; then
            echo "🔄 Restarting all ArgoCD pods..."
            kubectl delete pod -n argocd --all
          else
            echo "✅ Enough ArgoCD pods are already running."
          fi

      - name: Install NGINX Ingress Controller
        run: |
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo update
          helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
            --namespace ingress-nginx \
            --create-namespace
      - name: ⏱️ Wait for NGINX Admission Webhook
        run: |
          echo "Waiting for ingress-nginx admission webhook to become ready..."
          kubectl wait --namespace ingress-nginx \
            --for=condition=Available deployment/ingress-nginx-controller \
            --timeout=120s
          kubectl get svc ingress-nginx-controller-admission -n ingress-nginx

      - name: Apply ArgoCD Ingress
        run: |
          echo "Applying Ingress resource for ArgoCD..."
          kubectl apply -f argocd/argocd-ingress.yaml

      - name: Patch ArgoCD Server Service to ClusterIP (ensure NGINX compatibility)
        run: |
          echo "🔧 Ensuring argocd-server service is set to ClusterIP..."
          kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "ClusterIP"}}' || true

      - name: Prompt for Access Preference
        run: |
          echo "🌐 Do you want to expose ArgoCD via:"
          echo "1. A custom hostname (like argocd.example.com)"
          echo "2. Or just use the NGINX LoadBalancer IP for now"
          echo "Update your DNS or test with the IP shown below."

      - name: Get NGINX Ingress Controller External IP
        run: |
          echo "🌐 Retrieving external IP for NGINX Ingress..."
          for i in {1..10}; do
            INGRESS_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            if [[ -n "$INGRESS_IP" ]]; then
              echo "✅ NGINX Ingress Controller External IP: $INGRESS_IP"
              echo "Access ArgoCD at: http://$INGRESS_IP"
              break
            fi
            echo "⏳ Waiting for Ingress external IP..."
            sleep 10
          done

      - name: Apply ArgoCD Application
        run: |
          sed -i "s|AWS_ACCOUNT_ID|${{ secrets.AWS_ACCOUNT_ID }}|g" argocd/application.yaml
          kubectl apply -f argocd/application.yaml

      - name: Ensure demo-app Namespace Exists
        run: |
          if ! kubectl get namespace demo-app; then
            kubectl create namespace demo-app
          fi

      - name: Build and Push Node.js App to ECR
        run: |
          IMAGE_TAG=${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com/nodejs-app:latest

          echo "🛠 Building Docker image..."
          docker build -t nodejs-app .

          echo "🏷 Tagging image as $IMAGE_TAG"
          docker tag nodejs-app:latest $IMAGE_TAG

          echo "🚀 Pushing image to ECR..."
          docker push $IMAGE_TAG

          kubectl create secret docker-registry ecr-secret \
            --docker-server="${{ secrets.AWS_ACCOUNT_ID }}.dkr.ecr.${{ secrets.AWS_REGION }}.amazonaws.com" \
            --docker-username=AWS \
            --docker-password="$(aws ecr get-login-password --region ${{ secrets.AWS_REGION }})" \
            --docker-email=none || true

      - name: Ensure demo-app Namespace Exists
        run: |
          if ! kubectl get namespace demo-app; then
            kubectl create namespace demo-app
          fi


      - name: Wait for ArgoCD Application Sync
        run: |
          sleep 30
          argocd app wait demo-app --sync --health || true




      - name: Log into ArgoCD (Ignoring Certificate Errors)
        run: |
          echo "🔑 Attempting to log into ArgoCD..."
          for i in {1..5}; do
            if argocd login $ARGOCD_SERVER --username admin --password "password" --insecure; then
              echo "✅ Successfully logged into ArgoCD"
              exit 0
            fi
            echo "⏳ Login failed. Retrying in 20s..."
            sleep 20
          done
          echo "❌ ERROR: ArgoCD login failed"
          exit 1

      - name: Wait for ArgoCD Server to Be Ready
        run: |
          echo "🔄 Waiting for ArgoCD server to be ready..."
          for i in {1..10}; do
            if kubectl get pods -n argocd | grep -q "argocd-server.*Running"; then
              echo "✅ ArgoCD server is running!"
              exit 0
            fi
            echo "⏳ ArgoCD server not ready yet. Retrying in 10s..."
            sleep 10
          done
          echo "❌ ERROR: ArgoCD server did not start in time."
          exit 1

      # - name: Start Port-Forwarding for ArgoCD
      #   run: |
      #     echo "🔄 Starting port-forwarding to ArgoCD..."
      #     kubectl port-forward svc/argocd-server -n argocd 8085:443 > /dev/null 2>&1 & echo $! > port_forward_pid
      #     sleep 5
      #     echo "✅ Port-forwarding started successfully"
    
      - name: Start Port-Forwarding for ArgoCD
        run: |
          echo "🔄 Starting port-forwarding to ArgoCD..."
          kubectl port-forward svc/argocd-server -n argocd 8085:443 > port_forward.log 2>&1 & echo $! > port_forward_pid
          sleep 5
          if ! ps -p $(cat port_forward_pid) > /dev/null; then
            echo "❌ Port-forwarding process failed to start"
            exit 1
          fi
          echo "✅ Port-forwarding started successfully"


      - name: Ensure ArgoCD Server is Reachable
        run: |
          echo "🔍 Checking if ArgoCD is reachable..."
          for i in {1..5}; do
            if nc -z localhost 8085; then
              echo "✅ ArgoCD is accessible on localhost:8085"
              exit 0
            fi
            echo "⏳ Waiting for ArgoCD port-forward..."
            sleep 5
          done
          echo "❌ ERROR: Could not connect to ArgoCD on localhost:8085"



      - name: Ensure ArgoCD CLI Recognizes 'admin'
        run: |
          echo "🔍 Checking ArgoCD account permissions..."
          argocd account get --server=localhost:8085 || (echo "❌ 'admin' account missing, failing job" && exit 1)
          echo "✅ ArgoCD account verified"
          

      - name: Ensure 'default' Project Exists
        run: |
          echo "🔧 Checking if 'default' project exists..."
          if ! argocd proj get default; then
            echo "🔄 Creating 'default' project..."
            argocd proj create default
          fi
          echo "✅ 'default' project exists"

      - name: Ensure 'admin' Role Exists in Project
        run: |
          echo "🔧 Checking if 'admin' role exists in 'default' project..."
          if ! argocd proj role list default | grep -q "admin"; then
            echo "🔄 Creating 'admin' role in 'default' project..."
            argocd proj role create default admin
          fi
          echo "✅ 'admin' role exists in 'default' project"





      - name: Assign Full Sync Permissions to 'admin' Role
        run: |
          echo "🔧 Assigning full sync permissions to 'admin' role..."
          argocd proj role add-policy default admin -a get -o applications/* -p allow
          argocd proj role add-policy default admin -a sync -o applications/* -p allow
          argocd proj role add-policy default admin -a update -o applications/* -p allow
          argocd proj role add-policy default admin -a override -o applications/* -p allow
          argocd proj role add-policy default admin -a create -o applications/* -p allow
          argocd proj role add-policy default admin -a delete -o applications/* -p allow
          echo "✅ Permissions updated"


      - name: Assign Full Project-Level Permissions to 'admin' Role
        run: |
          echo "🔧 Assigning project-level permissions to 'admin' role..."
          argocd proj role add-policy default admin -a get -o projects/default -p allow
          argocd proj role add-policy default admin -a update -o projects/default -p allow
          argocd proj role add-policy default admin -a sync -o projects/default -p allow
          argocd proj role add-policy default admin -a override -o projects/default -p allow
          echo "✅ Project-level permissions assigned"

      - name: Assign Application-Level Access to 'admin' Role
        run: |
          echo "🔧 Assigning explicit permissions for 'admin' role on 'demo-app'..."
          argocd proj role add-policy default admin -a get -o applications/demo-app -p allow
          argocd proj role add-policy default admin -a update -o applications/demo-app -p allow
          argocd proj role add-policy default admin -a sync -o applications/demo-app -p allow
  
       

          echo "✅ 'admin' role permissions for 'demo-app' updated"


      - name: Assign Namespace & Cluster-Level Access
        run: |
          echo "🔧 Assigning namespace and cluster-level access to 'admin' role..."
          argocd proj allow-cluster-resource default "*" "*"
          argocd proj allow-namespace-resource default "*" "*"
          echo "✅ Namespace and cluster-wide access granted"



      
      - name: Ensure Global ArgoCD Authorization for 'admin'
        run: |
          echo "🔧 Ensuring 'admin' is globally authorized in ArgoCD..."
          kubectl patch configmap argocd-cm -n argocd --type merge -p \
            '{"data":{" policy.default":" role: admin"}}'
          echo "✅ Global authorization applied"
          
      - name: 🔧 Update ArgoCD RBAC settings
        run: |
          echo "🔧 Updating ArgoCD RBAC settings..."
      
          kubectl patch configmap argocd-rbac-cm -n argocd --type merge -p \
          '{"data": {"policy.csv": "g, my-group, role:admin\ng, dev-team, role:readonly"}}'
      
          echo "✅ ArgoCD RBAC settings updated successfully!"


          
      - name: Ensure ArgoCD Controller Has Full Cluster Access
        run: |
          echo "🔧 Granting cluster-admin access to ArgoCD controller..."
          kubectl create clusterrolebinding argocd-admin-binding --clusterrole=cluster-admin --serviceaccount=argocd:argocd-application-controller || true
          echo "✅ ArgoCD controller has cluster-admin access"

          


      
      - name: Restart ArgoCD Server to Apply Authorization Changes
        run: |
          echo "🔄 Restarting ArgoCD to apply changes..."
          kubectl rollout restart deployment argocd-server -n argocd
          sleep 30
          echo "✅ Restart complete"

      - name: Log into ArgoCD (Ignoring Certificate Errors)
        run: |
          echo "🔑 Attempting to log into ArgoCD..."
          for i in {1..5}; do
            if argocd login $ARGOCD_SERVER --username admin --password "password" --insecure; then
              echo "✅ Successfully logged into ArgoCD"
              exit 0
            fi
            echo "⏳ Login failed. Retrying in 20s..."
            sleep 20
          done
          echo "❌ ERROR: ArgoCD login failed"
          exit 1

      - name: Wait for ArgoCD Server to Be Ready
        run: |
          echo "🔄 Waiting for ArgoCD server pods to be ready..."
          for i in {1..10}; do
            if kubectl get pods -n argocd | grep -q "argocd-server.*Running"; then
              echo "✅ ArgoCD server is running!"
              exit 0
            fi
            echo "⏳ ArgoCD server not ready yet. Retrying in 10s..."
            sleep 10
          done
          echo "❌ ERROR: ArgoCD server did not start in time."
          exit 1

      - name: Start Port-Forwarding for ArgoCD
        run: |
          echo "🔄 Checking if another process is using port 8085..."
          kill -9 $(lsof -t -i :8085) 2>/dev/null || true
          
          echo "🔄 Checking available ports on argocd-server..."
          kubectl get svc argocd-server -n argocd -o yaml | grep "port:"

          echo "🔄 Starting port-forwarding to ArgoCD..."
          nohup kubectl port-forward svc/argocd-server -n argocd 8085:443 > port_forward.log 2>&1 & echo $! > port_forward_pid
          sleep 5
          
          if ! ps -p $(cat port_forward_pid) > /dev/null; then
            echo "❌ Port-forwarding process failed to start"
            exit 1
          fi
          
          echo "✅ Port-forwarding started successfully"

      - name: Ensure ArgoCD Server is Reachable
        run: |
          echo "🔍 Checking if ArgoCD is reachable..."
          for i in {1..5}; do
            if nc -z localhost 8085; then
              echo "✅ ArgoCD is accessible on localhost:8085"
              exit 0
            fi
            echo "⏳ Waiting for ArgoCD port-forward..."
            sleep 5
          done
          echo "❌ ERROR: Could not connect to ArgoCD on localhost:8085"
          exit 1


      - name: Verify Port-Forwarding is Still Active
        run: |
          echo "🔍 Checking if port-forwarding is still active..."
          if ! ps -p $(cat port_forward_pid) > /dev/null; then
            echo "⚠️ Port-forwarding process is missing. Restarting..."
            kubectl port-forward svc/argocd-server -n argocd 8085:443 > port_forward.log 2>&1 & echo $! > port_forward_pid
            sleep 5
          fi
          echo "✅ Port-forwarding process is running"

      - name: Debug - Verify 'admin' Role Permissions in ArgoCD
        run: |
          echo "🔍 Checking 'admin' role permissions in ArgoCD..."
          argocd proj role get default admin --server=localhost:8085 || (echo "❌ 'admin' role missing or has incorrect permissions!" && exit 1)
          echo "✅ 'admin' role permissions verified"

      - name: 🔍 Checking if 'demo-app' exists...
        run: argocd app list

              
      - name: Recreate ArgoCD Application
        run: |
          echo "🚀 Recreating ArgoCD application..."
          kubectl delete -f argocd/application.yaml --ignore-not-found
          sed -i "s|AWS_ACCOUNT_ID|${{ secrets.AWS_ACCOUNT_ID }}|g" argocd/application.yaml
          kubectl apply -f argocd/application.yaml

          kubectl apply -f argocd/application.yaml

      - name: 🔍 Checking if 'demo-app' exists222..
        run: argocd app list    

          
      - name: Debug - Check ArgoCD Logs for RBAC Issues
        run: |
          echo "🔍 Checking ArgoCD logs for RBAC rejections..."
          kubectl logs -n argocd -l app.kubernetes.io/name=argocd-server | grep "RBAC" || echo "✅ No RBAC rejections found"
    
      - name: Debug - List Applications to Check Ownership
        run: |
          echo "🔍 Listing ArgoCD applications..."
          argocd app list --server=localhost:8085
          echo "✅ ArgoCD applications listed"
          
      - name: Debug - Verify 'demo-app' Exists Before Assignment
        run: |
          echo "🔍 Checking if 'demo-app' exists..."
          if ! argocd app get demo-app --server=localhost:8085; then
            echo "❌ 'demo-app' does not exist or is inaccessible."
            exit 1
          fi
          echo "✅ 'demo-app' exists and is accessible."



      - name: Debug - Check If 'admin' Can Access 'demo-app'
        run: |
          echo "🔍 Checking if 'admin' can get 'demo-app'..."
          if ! argocd app get demo-app --server=localhost:8085; then
            echo "❌ 'admin' cannot access 'demo-app'. This is likely an RBAC issue!"
            exit 1
          fi
          echo "✅ 'admin' has access to 'demo-app'"

          
      - name: Ensure 'demo-app' Is Assigned to 'default' Project
        run: |
          echo "🔍 Checking if 'admin' owns 'demo-app'..."
          argocd app set demo-app --project default --server=localhost:8085
          echo "✅ 'demo-app' ownership reassigned to 'default' proj



      - name: Ensure 'demo-app' Ownership
        run: |
          echo "🔍 Checking if 'admin' owns 'demo-app'..."
          argocd app get demo-app --server=localhost:8085 || \
          argocd app set demo-app --project default --server=localhost:8085
          echo "✅ Ownership verified"

    
      - name: Verify 'admin' Role Permissions
        run: |
          echo "🔍 Verifying 'admin' role permissions..."
          argocd proj role get default admin

      - name: Sync ArgoCD Application
        run: |
          echo "🚀 Syncing demo-app with ArgoCD..."
          argocd app sync demo-app --server=$ARGOCD_SERVER
          echo "✅ Sync initiated successfully"

      - name: Port Forward as Fallback
        if: failure()
        run: |
          echo "⚠️ Using port-forwarding as a fallback..."
          kubectl port-forward svc/argocd-server -n argocd 8085:443 > /dev/null 2>&1 & echo $! > port_forward_pid
          sleep 5

          echo "🔑 Logging into ArgoCD via port-forward..."
          argocd login localhost:8085 --username admin --password "password" --insecure
          echo "✅ Successfully logged in using port-forwarding"

          echo "🚀 Syncing demo-app with ArgoCD via port-forward..."
          argocd app sync demo-app --server=localhost:8085 || (echo "❌ Sync failed via port-forwarding." && exit 1)
          echo "✅ Sync initiated successfully (fallback mode)"

          echo "🛑 Cleaning up port-forwarding..."
          kill $(cat port_forward_pid)


    
   
